# 🚀 性能优化方案

## 📊 当前状态

- **单局时间：** 1.7分钟
- **每轮时间：** 2.8小时（100局）
- **已优化：** 4.5倍提速
- **瓶颈：** MCTS搜索（每步50次模拟）

---

## 🎯 优化策略（按效果排序）

### 🥇 方案1：动态MCTS模拟次数（预计2-3倍加速）

**原理：** 训练初期AI随机走棋，不需要深度思考

**实施：**
```python
# config.py
# 根据训练进度动态调整MCTS模拟次数
def get_mcts_simulations(total_games):
    if total_games < 500:
        return 20   # 初期：快速探索
    elif total_games < 2000:
        return 30   # 中期：逐渐加强
    elif total_games < 5000:
        return 40
    else:
        return 50   # 后期：完整思考
```

**效果：**
- 前500局：20次模拟 → 单局**40秒**（2.5倍加速）
- 前2000局：30次模拟 → 单局**1分钟**（1.7倍加速）
- **每轮时间降至：1.1小时（前期）**

---

### 🥈 方案2：多进程自我对弈（预计3-4倍加速）

**原理：** CPU有多核，并行执行多局对弈

**实施：**
```python
# self_play.py
import multiprocessing as mp

def parallel_self_play(network, num_games, num_workers=4):
    """并行自我对弈"""
    with mp.Pool(num_workers) as pool:
        results = pool.starmap(
            self_play_game,
            [(network, temperature) for _ in range(num_games)]
        )
    return results
```

**效果：**
- 4核CPU：4局同时进行
- **每轮时间：0.7小时**（4倍加速）

**注意：** 需要处理PyTorch模型序列化

---

### 🥉 方案3：降低温度参数（预计10-15%加速）

**原理：** 更确定的选择，减少随机性

**实施：**
```python
# self_play.py
def self_play_game(network, temperature=0.3):  # 降低默认温度
    # 温度越低，越倾向于选择最优走法
    # 减少softmax计算开销
```

**效果：**
- 更快的走法选择
- **每轮时间：2.4小时**

---

### 方案4：优化神经网络（预计20-30%加速）

**原理：** 减小网络规模，提高推理速度

**实施：**
```python
# neural_network.py
class ChessNet(nn.Module):
    def __init__(self, channels=128):  # 降低通道数（原256）
        # 或使用MobileNet等轻量架构
```

**效果：**
- 更快的前向传播
- **每轮时间：2.0小时**

**权衡：** 可能影响棋力上限

---

### 方案5：批处理优化（已实现，可调整）

**当前状态：** 已有批量推理

**进一步优化：**
```python
# 增大批处理大小
BATCH_SIZE = 128  # 从64增加到128

# 使用混合精度训练
with torch.cuda.amp.autocast():
    policy, value = network(states)
```

**效果：**
- GPU利用率提升
- **额外5-10%加速**

---

### 方案6：减少训练频率（实用技巧）

**原理：** 不是每轮都训练神经网络

**实施：**
```python
# trainer.py
if iteration % 2 == 0:  # 每2轮训练一次
    self.train_network()
```

**效果：**
- 训练时间减半
- **每轮时间：1.4小时**

**权衡：** 模型收敛稍慢

---

## 🎨 推荐组合方案

### 🌟 激进方案（最快）

组合：方案1（动态MCTS）+ 方案2（多进程）+ 方案6（减少训练）

**预期效果：**
- **单局：25秒**（前期）
- **每轮：0.4小时（25分钟）**
- **总加速：7倍**

**适用于：** 快速验证想法，前期训练

---

### ⚖️ 平衡方案（推荐）

组合：方案1（动态MCTS）+ 方案3（降温度）

**预期效果：**
- **单局：35秒**（前期）
- **每轮：1.0小时**
- **总加速：2.8倍**

**适用于：** 日常训练，平衡速度和质量

---

### 🎯 质量优先方案

组合：方案1（仅前期降低MCTS）+ 方案5（批处理优化）

**预期效果：**
- **单局：1.2分钟**（前期）
- **每轮：2.0小时**
- **总加速：1.4倍**

**适用于：** 追求最佳棋力

---

## 🛠️ 立即可实施的优化

### 1️⃣ 快速优化（5分钟）

修改`config.py`：
```python
# 降低MCTS模拟次数（训练前期）
MCTS_SIMULATIONS = 25  # 从50降到25

# 减少训练频率
TRAIN_INTERVAL = 2  # 每2轮训练一次
```

**效果：** 2倍加速，每轮1.4小时

---

### 2️⃣ 动态MCTS（15分钟）

在`trainer.py`中实现动态调整：

```python
def get_mcts_simulations(self):
    """根据训练进度动态调整MCTS模拟次数"""
    if self.total_games < 500:
        return 20
    elif self.total_games < 2000:
        return 30
    else:
        return 50

# 在collect_self_play_data中使用
def collect_self_play_data(self, num_games):
    simulations = self.get_mcts_simulations()
    # 传递给self_play_game
```

**效果：** 前期2.5倍加速

---

### 3️⃣ 多进程（1小时）

需要重构`self_play.py`，处理进程间通信

**复杂度：** 中等
**效果：** 3-4倍加速

---

## 📈 性能对比

| 方案 | 单局时间 | 每轮时间 | 实施难度 | 棋力影响 |
|------|---------|---------|---------|---------|
| 当前 | 1.7分钟 | 2.8小时 | - | - |
| 快速优化 | 50秒 | 1.4小时 | ⭐ | 微小 |
| 动态MCTS | 40秒 | 1.1小时 | ⭐⭐ | 无（前期）|
| 多进程 | 25秒 | 0.7小时 | ⭐⭐⭐ | 无 |
| 激进方案 | 25秒 | 0.4小时 | ⭐⭐⭐ | 小 |

---

## 🎲 其他优化建议

### GPU优化
```python
# 启用cudnn自动优化
torch.backends.cudnn.benchmark = True

# 固定内存加速数据传输
states = states.pin_memory().to(DEVICE, non_blocking=True)
```

### 代码优化
```python
# 使用numpy向量化替代循环
# chess_env.py中的走法生成可以进一步优化

# 缓存合法走法哈希
self.legal_moves_cache = {}
```

### 环境复制优化（已实现）
```python
# 使用copy.deepcopy替代手动复制
import copy
env_copy = copy.deepcopy(env)
```

---

## 💡 我的建议

**对于您的情况（RTX 4070 + 已训练189局）：**

### 🚀 推荐：平衡方案

**实施步骤：**
1. 修改`config.py`：
   ```python
   MCTS_SIMULATIONS = 25  # 降低到25（您还在前500局内）
   ```

2. 添加动态调整（可选）：
   - 在`trainer.py`中实现`get_mcts_simulations()`
   - 500局后自动增加到30，2000局后增加到50

**预期效果：**
- 前500局：单局50秒，每轮1.4小时（节省1.4小时）
- 500-2000局：单局1.0分钟，每轮1.7小时
- 2000局后：恢复全速，单局1.7分钟

**总节省时间：**
- 前10轮：节省14小时
- 足够跑到500局（入门级）

---

## 📝 实施建议

### 阶段1：立即实施（今天）
- ✅ 降低MCTS到25
- ✅ 减少训练频率（可选）

### 阶段2：短期实施（本周）
- 🔄 实现动态MCTS调整
- 🔄 优化神经网络（降低通道数）

### 阶段3：长期实施（下周）
- 📅 多进程自我对弈
- 📅 混合精度训练

---

## ⚠️ 注意事项

1. **保存当前模型**：优化前备份`models/latest.pt`
2. **逐步测试**：一次实施一个优化，观察效果
3. **监控棋力**：用`compare_models.py`对比优化前后
4. **GPU监控**：用`nvidia-smi`确保GPU利用率

---

您想先实施哪个方案？我可以帮您立即修改代码！
